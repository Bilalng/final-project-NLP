# DoÄŸal Dil Ä°ÅŸleme ile AraÃ§ ArÄ±za Analizi

## Proje Genel BakÄ±ÅŸ

Bu proje, Reddit'ten toplanan araÃ§ arÄ±zalarÄ± ile ilgili tartÄ±ÅŸmalarÄ± analiz etmek iÃ§in DoÄŸal Dil Ä°ÅŸleme (NLP) tekniklerini uygulamaktadÄ±r. Uygulama, metin Ã¶n iÅŸleme, Zipf yasasÄ± analizi, TF-IDF vektÃ¶rleÅŸtirme ve araÃ§ arÄ±za aÃ§Ä±klamalarÄ± Ã¼zerinde farklÄ± parametrelerle eÄŸitilen Ã§oklu Word2Vec modellerini iÃ§ermektedir.

## Proje AmaÃ§larÄ±

Reddit'ten toplanan araÃ§ arÄ±za veri seti ÅŸunlar iÃ§in kullanÄ±labilir:

- AraÃ§ arÄ±za tartÄ±ÅŸmalarÄ±ndaki yaygÄ±n kalÄ±plarÄ± ve trendleri analiz etme
- Otomotiv problem aÃ§Ä±klamalarÄ±nÄ±n dilbilimsel Ã¶zelliklerini anlama
- Otomotiv forumlarÄ± iÃ§in anlamsal arama yetenekleri geliÅŸtirme
- ArÄ±za aÃ§Ä±klamalarÄ±na dayalÄ± Ã¶neri sistemleri oluÅŸturma
- Metinsel aÃ§Ä±klamalara dayalÄ± benzer araÃ§ problemlerini tanÄ±mlama
- AraÃ§ arÄ±za raporlarÄ±ndan Ã¶nemli Ã¶zellikleri ve belirtileri Ã§Ä±karma

## ğŸ—‚ï¸ Depo YapÄ±sÄ±

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cleaned-reduced-data-set/         # TemizlenmiÅŸ ve Ã¶n iÅŸlenmiÅŸ veri
â”‚   â”‚   â”œâ”€â”€ corpus_lemmatized.csv
â”‚   â”‚   â””â”€â”€ corpus_stemmed.csv
â”‚   â”œâ”€â”€ processed/                        # Ä°ÅŸlenmiÅŸ veri dosyalarÄ±
â”‚   â”œâ”€â”€ raw-data-set/                     # Reddit'ten alÄ±nan ham JSON verisi
â”‚   â”œâ”€â”€ reduced-the-data-set/             # FiltrelenmiÅŸ/azaltÄ±lmÄ±ÅŸ veri seti
â”‚   â”œâ”€â”€ similar_words/                    # Kelime benzerliÄŸi Ã§Ä±ktÄ±larÄ±
â”‚   â””â”€â”€ tf-idf-score/                     # TF-IDF vektÃ¶rleÅŸtirme sonuÃ§larÄ±
â”œâ”€â”€ models/                               # EÄŸitilmiÅŸ Word2Vec modelleri
â”œâ”€â”€ plots/                                # OluÅŸturulmuÅŸ gÃ¶rselleÅŸtirmeler 
â””â”€â”€ scripts/                              # Veri iÅŸleme iÃ§in Python KodlarÄ±
```

## Kurulum ve Ayarlar

### Ã–n KoÅŸullar

- Python 3.8 veya daha Ã¼st sÃ¼rÃ¼mÃ¼

### Ortam Kurulumu

1. Sanal ortam oluÅŸturun:
   ```bash
   python -m venv venv
   ```

2. Sanal ortamÄ± etkinleÅŸtirin:
   - Windows:
     ```bash
     venv\Scripts\activate
     ```
   - Unix/MacOS:
     ```bash
     source venv/bin/activate
     ```

3. Gerekli paketleri yÃ¼kleyin:
   ```bash
   pip install -r requirements.txt
   ```

## Veri Ä°ÅŸleme AdÄ±mlarÄ±

### 1. Veri Toplama

Proje, Reddit'ten araÃ§ arÄ±za tartÄ±ÅŸmalarÄ±nÄ±n toplanmasÄ±yla baÅŸlar:

```bash
python scripts/recieve-data-in-reddit.py
```

### 2. Veri Azaltma

Veri setini ilgili araÃ§ arÄ±za iÃ§eriÄŸine odaklanacak ÅŸekilde filtreleme ve azaltma:

```bash
python scripts/reduce-data-set.py
```

### 3. Veri Ã–n Ä°ÅŸleme

Metin verilerini temizleme ve Ã¶n iÅŸleme:

```bash
python scripts/cleandata.py
```

Bu adÄ±m ÅŸunlarÄ± iÃ§erir:
- Metin temizleme
- Tokenizasyon
- Durak kelimeleri (stop words) kaldÄ±rma
- Lemmatizasyon ve kÃ¶k bulma (stemming) (iki ayrÄ± veri seti oluÅŸturma)

### 4. Zipf Analizi

Korpustaki kelime frekans daÄŸÄ±lÄ±mlarÄ±nÄ± analiz etme:

```bash
python scripts/ziph_analysis.py
```

### 5. TF-IDF VektÃ¶rleÅŸtirme

Metnin TF-IDF temsillerini oluÅŸturma:

```bash
python scripts/tfidf_vectorizater.py
```

### 6. Word2Vec Model EÄŸitimi

FarklÄ± parametrelerle Ã§oklu Word2Vec modellerini eÄŸitme:

```bash
python scripts/create_model.py
```

EÄŸitim sÃ¼reci ÅŸunlarÄ± iÃ§erir:
- CBOW ve Skip-gram mimarileri
- FarklÄ± pencere boyutlarÄ± (2 ve 5)
- Ã‡eÅŸitli vektÃ¶r boyutlarÄ± (100 ve 300)
- Hem lemmatize edilmiÅŸ hem de kÃ¶kleri bulunan (stemmed) versiyonlar

### 7. Model DeÄŸerlendirme

EÄŸitilen modelleri deÄŸerlendirme:

```bash
python scripts/modeltest.py
```

## Word2Vec Modelleri

Proje, farklÄ± parametrelerle eÄŸitilmiÅŸ 16 farklÄ± Word2Vec modelini iÃ§ermektedir:

| Model Tipi | Pencere Boyutu | VektÃ¶r Boyutu | Mimari    | Metin Ä°ÅŸleme  |
|------------|----------------|---------------|-----------|---------------|
| Word2Vec   | 2              | 100           | CBOW      | Lemmatized    |
| Word2Vec   | 2              | 100           | Skip-gram | Lemmatized    |
| Word2Vec   | 2              | 300           | CBOW      | Lemmatized    |
| Word2Vec   | 2              | 300           | Skip-gram | Lemmatized    |
| Word2Vec   | 5              | 100           | CBOW      | Lemmatized    |
| Word2Vec   | 5              | 100           | Skip-gram | Lemmatized    |
| Word2Vec   | 5              | 300           | CBOW      | Lemmatized    |
| Word2Vec   | 5              | 300           | Skip-gram | Lemmatized    |
| Word2Vec   | 2              | 100           | CBOW      | Stemmed       |
| Word2Vec   | 2              | 100           | Skip-gram | Stemmed       |
| Word2Vec   | 2              | 300           | CBOW      | Stemmed       |
| Word2Vec   | 2              | 300           | Skip-gram | Stemmed       |
| Word2Vec   | 5              | 100           | CBOW      | Stemmed       |
| Word2Vec   | 5              | 100           | Skip-gram | Stemmed       |
| Word2Vec   | 5              | 300           | CBOW      | Stemmed       |
| Word2Vec   | 5              | 300           | Skip-gram | Stemmed       |

## GÃ¶rselleÅŸtirmeler

Proje birkaÃ§ gÃ¶rselleÅŸtirme iÃ§erir:

- Kelime frekans daÄŸÄ±lÄ±mlarÄ± (Zipf yasasÄ±)
- Word2Vec vektÃ¶r gÃ¶sterimleri
- Kelime daÄŸarcÄ±ÄŸÄ± boyutu karÅŸÄ±laÅŸtÄ±rmalarÄ±
- Model performans metrikleri

Bu gÃ¶rselleÅŸtirmeleri `plots/` dizininde gÃ¶rÃ¼ntÃ¼leyebilirsiniz.

## Notlar

- BÃ¼yÃ¼k dosyalar (>100MB) depodan hariÃ§ tutulmuÅŸtur.
- TÃ¼m modeller, araÃ§ arÄ±zalarÄ±na odaklanan temizlenmiÅŸ ve Ã¶n iÅŸlenmiÅŸ bir Reddit veri alt kÃ¼mesi Ã¼zerinde eÄŸitilmiÅŸtir.
- KÃ¶klenmiÅŸ (stemmed) ve lemmatize edilmiÅŸ veri setleri, aynÄ± metinsel iÃ§erik Ã¼zerinde farklÄ± perspektifler sunar.


