import json
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1ï¸âƒ£ TemizlenmiÅŸ veriyi oku (lemmatized olan)
with open("corpus_lemmatized.json", "r", encoding="utf-8") as f:
    corpus = json.load(f)

# 2ï¸âƒ£ Token listelerini tekrar metin haline getir
lemmatized_texts = [' '.join(tokens) for tokens in corpus]

# 3ï¸âƒ£ Metinleri CSV olarak kaydet (her satÄ±r bir metin)
df_texts = pd.DataFrame(lemmatized_texts, columns=["text"])
df_texts.to_csv("lemmatized_texts.csv", index=False, encoding="utf-8")
print("ğŸ“„ Token'lar metinleÅŸtirilip kaydedildi â†’ lemmatized_texts.csv")

# 4ï¸âƒ£ TF-IDF iÅŸlemi
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(lemmatized_texts)

# 5ï¸âƒ£ Ã–zellik isimlerini al ve TF-IDF skorlarÄ±nÄ± DataFrame'e Ã§evir
feature_names = vectorizer.get_feature_names_out()
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)

# 6ï¸âƒ£ TF-IDF skorlarÄ±nÄ± CSV olarak kaydet
tfidf_df.to_csv("tfidf_scores.csv", index=False, encoding="utf-8")
print("ğŸ“Š TF-IDF skorlarÄ± kaydedildi â†’ tfidf_scores.csv")

# 7ï¸âƒ£ Ä°lk cÃ¼mledeki en yÃ¼ksek TF-IDF skorlu 5 kelime
first_sentence_vector = tfidf_df.iloc[0]
top_5_words = first_sentence_vector.sort_values(ascending=False).head(5)

print("\nğŸ” Ä°lk aÃ§Ä±klamadaki en Ã¶nemli 5 kelime (TF-IDF):")
print(top_5_words)

# 8ï¸âƒ£ "engine" kelimesine en benzer kelimeleri bul
target_word = "engine"
try:
    index = feature_names.tolist().index(target_word)
    word_vector = tfidf_matrix[:, index].toarray()
    all_vectors = tfidf_matrix.toarray()
    similarities = cosine_similarity(word_vector.T, all_vectors.T).flatten()
    top_indices = similarities.argsort()[-6:][::-1]

    print(f"\nğŸ”— '{target_word}' kelimesine en benzeyen kelimeler:")
    for idx in top_indices:
        print(f"{feature_names[idx]}: {similarities[idx]:.4f}")
except ValueError:
    print(f"\nâš ï¸ Kelime bulunamadÄ±: {target_word}")
